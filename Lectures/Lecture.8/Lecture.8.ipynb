{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 8\n",
    "\n",
    "## Reading Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat Scores.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comma Separated Values (CSV) File Format\n",
    "\n",
    "The simplest and most common file format for storing data is called Comma Separated Values (CSV). Generally a CSV file represents a table, with the top row (first line of the file) consisting of the labels of the columns (separated by commas). Generally each column keeps a different feature or field. For example for student data, the first column could be the name, second the ID, third major, etc. After the first line, each row hold the data for one data point or example. In the case of student data, each row could correspond to one student."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading CSV Files\n",
    "\n",
    "There are lots of libraries for reading CSV files into memory. Before we start using them, lets write our own. We'll need two things:\n",
    "\n",
    "* Means of reading and interpreting the file.\n",
    "* A representation of the read data in memory.\n",
    "\n",
    "Lets recall one of the ways in python to read a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f=open(\"Scores.csv\",\"r\")\n",
    "\n",
    "first_line = f.readline()\n",
    "print(first_line)\n",
    "\n",
    "line = f.readline()\n",
    "while line:\n",
    "    print(line)\n",
    "    line = f.readline()\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We successfully dumped the contents of the file, but we didn't \n",
    "\n",
    "* interpret it... each line is just a string no a camma separated list of keys or values. \n",
    "* or store it into memory... we just dumped it into the screen.\n",
    "\n",
    "Let's start on properly interpreting the first line, which is special:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"Scores.csv\",\"r\")\n",
    "first_line = f.readline()\n",
    "print(first_line.split(\",\"))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that each line ends with `\\n`. Here's how we can remove these newlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"Scores.csv\",\"r\")\n",
    "first_line = f.readline().rstrip()\n",
    "print(first_line.split(\",\"))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally lets store the first line, which is a list of the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"Scores.csv\",\"r\")\n",
    "first_line = f.readline().rstrip()\n",
    "keys=first_line.split(\",\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets read the rest of the file in a similar fashion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"Scores.csv\",\"r\")\n",
    "first_line = f.readline().rstrip()\n",
    "keys=first_line.split(\",\")\n",
    "\n",
    "data=list()\n",
    "\n",
    "line = f.readline().rstrip()\n",
    "while line:\n",
    "    data.append(line.split(\",\"))\n",
    "    line = f.readline().rstrip()\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have everything in memory now, how do we retrieve it?\n",
    "\n",
    "To associate specific keys to column numbers, we can do the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields.index(\"l4_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the 10th student \"l4_1\" grade is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[10][fields.index(\"l4_1\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it's still a string... not a number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data[10][fields.index(\"l4_1\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a CSV Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the basics down, but we have more things to consider:\n",
    "* We have written some example code, we should now write something that is general and we could use in different instances. \n",
    "* The fields can be different types: strings, numbers (integer or floating point). We should store the fields as the correct data type.\n",
    "* Still need to figure out how we will store the data in memory.\n",
    "\n",
    "\n",
    "We have some options on how to proceed:\n",
    "   * We could write a CSV reader function that given the filename of a CSV file, reads the data and returns it as a standard python data object. There are various suitable such representations, so we'll either have to pick one or provide some options to allow for other ones.\n",
    "   * Instead of a CSV reader function, we could create a CSV reader class. It will be instantiated with a CSV filename, so each instance would be uniquely connected to a specific file. It'll read the data into some representation that is kept private. We provide accessor methods to get to retrieve specific parts of the data, or the whole data as standard python data.\n",
    "   * We can separate the concepts of a CSV reader and how we store the data. In this way, we could write other readers (e.g. Excel file reader) that would still use the same data storage.\n",
    "   * We might want to also be able to write out CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following implementation of a file reader that leaves room for supporting other file formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFileHandler:\n",
    "    def __init__(self,extensions):\n",
    "        self.__extensions=extensions\n",
    "        \n",
    "    def check_extension(self,filename):\n",
    "        file_extension=filename.split(\".\")[-1]\n",
    "        return file_extension in self.__extensions\n",
    "\n",
    "    def _readfile(self,filename):\n",
    "        raise NotImplementedError    \n",
    "        \n",
    "    def readfile(self,filename,check_extension=True):\n",
    "        if not check_extension or self.check_extension(filename):\n",
    "            return self._readfile(filename)        \n",
    "        else:\n",
    "            print(\"Error: filename {} does not match acceptable extensions.\".format(filename))\n",
    "    \n",
    "    def _writefile(self,filename,data):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def writefile(self,filename,data):\n",
    "        return self._writefile(filename,data)\n",
    "        \n",
    "        \n",
    "class CSVHandler(DataFileHandler):\n",
    "    def __init__(self):\n",
    "        #super(CSVHandler,self).__init__([\"csv\",\"CSV\"])\n",
    "        DataFileHandler.__init__(self,[\"csv\",\"CSV\"])\n",
    "        \n",
    "    def _readfile(self,filename):\n",
    "        f=open(filename,\"r\")\n",
    "        first_line = f.readline().rstrip()\n",
    "        fields=first_line.split(\",\")\n",
    "\n",
    "        data=list()\n",
    "\n",
    "        line = f.readline().rstrip()\n",
    "        while line:\n",
    "            data.append(line.split(\",\"))\n",
    "            line = f.readline().rstrip()\n",
    "\n",
    "        f.close()\n",
    "        \n",
    "        return fields,data\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_handler=CSVHandler()\n",
    "fields,data=my_handler.readfile(\"Scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data[0][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Different Types\n",
    "\n",
    "When we read a text file, all the content is assumed to be composed of strings. Instead, ideally we would like to interpret the file by looking at each field and seeing selecting an appropriate type.\n",
    "\n",
    "In the following example, we attempt to first convert very field to a `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFileHandler:\n",
    "    def __init__(self,extensions):\n",
    "        self.__extensions=extensions\n",
    "        \n",
    "    def check_extension(self,filename):\n",
    "        file_extension=filename.split(\".\")[-1]\n",
    "        return file_extension in self.__extensions\n",
    "\n",
    "    def _readfile(self,filename):\n",
    "        raise NotImplementedError    \n",
    "        \n",
    "    def readfile(self,filename,check_extension=True):\n",
    "        if not check_extension or self.check_extension(filename):\n",
    "            return self._readfile(filename)        \n",
    "        else:\n",
    "            print(\"Error: filename {} does not match acceptable extensions.\".format(filename))\n",
    "    \n",
    "    def _writefile(self,filename,data):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def writefile(self,filename,data):\n",
    "        return self._writefile(filename,data)\n",
    "        \n",
    "        \n",
    "class CSVHandler(DataFileHandler):\n",
    "    def __init__(self):\n",
    "        #super(CSVHandler,self).__init__([\"csv\",\"CSV\"])\n",
    "        DataFileHandler.__init__(self,[\"csv\",\"CSV\"])\n",
    "        \n",
    "    def _readfile(self,filename):\n",
    "        f=open(filename,\"r\")\n",
    "        first_line = f.readline().rstrip()\n",
    "        fields=first_line.split(\",\")\n",
    "\n",
    "        data=list()\n",
    "\n",
    "        line = f.readline().rstrip()\n",
    "        while line:\n",
    "            items=line.split(\",\")\n",
    "            \n",
    "            row=list()\n",
    "            for item in items:\n",
    "                try:\n",
    "                    d=float(item)\n",
    "                except ValueError:\n",
    "                    d=item\n",
    "                row.append(d)\n",
    "            \n",
    "            data.append(row)\n",
    "            \n",
    "            line = f.readline().rstrip()\n",
    "\n",
    "        f.close()\n",
    "        \n",
    "        return fields,data\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_handler=CSVHandler()\n",
    "fields,data=my_handler.readfile(\"Scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Representation\n",
    "\n",
    "Since we are using a list of lists to contain the data of the CSV file in memory, we have to do a bit of manipulation to find specific fields in the list of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[10][fields.index(\"l4_1\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like we should use a dictionary instead... recall some basics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "foo=dict()\n",
    "foo[\"L1\"]=1\n",
    "foo[\"L2\"]=2\n",
    "\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo[\"L1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict([ (\"L1\",1), (\"L2\",2) ]  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in principle, we can then take every row and convert it easily to a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row=dict(list(zip(fields,data[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row[\"l4_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then store the dictionary for each row in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data=list()\n",
    "\n",
    "for row in data:\n",
    "    new_data.append(dict(list(zip(fields,row))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[10][\"l3_4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Data Class\n",
    "\n",
    "Our representation of a table as a list of dictionaries isn't the most efficient, but it is convenient. \n",
    "\n",
    "Lets try a different approach to storing the data that custom made for storing tables with rows of data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataRow:\n",
    "    def __init__(self,fields,data):\n",
    "        self.__fields=fields\n",
    "        self.__data=data\n",
    "        \n",
    "    def __getitem__(self,key):\n",
    "        return self.__data[self.__fields.index(key)]\n",
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.__fields=list()\n",
    "        self.__data=list()\n",
    "        \n",
    "    def set_fields(self,fields):\n",
    "        self.__fields=fields\n",
    "        \n",
    "    def add_data_point(self,data_point):\n",
    "        if isinstance(data_point,list):\n",
    "            if len(data_point) == len(self.__fields):\n",
    "                self.__data.append(DataRow(self.__fields,data_point))\n",
    "            else:\n",
    "                print(\"Expected {} fields, got {} fields.\".format(len(self.__fields),len(fields)))\n",
    "        else:\n",
    "            print(\"Data Point must be given as a list.\")\n",
    "\n",
    "    def add_data_points(self,data_points):\n",
    "        for data_point in data_points:\n",
    "            self.add_data_point(data_point)\n",
    "            \n",
    "    def fields(self):\n",
    "        return self.__fields\n",
    "    \n",
    "    def __getitem__(self,key):\n",
    "        return self.__data[key]\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data=Data()\n",
    "my_data.set_fields(fields)\n",
    "my_data.add_data_points(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data[12][\"l3_4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets put it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFileHandler:\n",
    "    def __init__(self,extensions):\n",
    "        self.__extensions=extensions\n",
    "        \n",
    "    def check_extension(self,filename):\n",
    "        file_extension=filename.split(\".\")[-1]\n",
    "        return file_extension in self.__extensions\n",
    "\n",
    "    def _readfile(self,filename):\n",
    "        raise NotImplementedError    \n",
    "        \n",
    "    def readfile(self,filename,check_extension=True):\n",
    "        if not check_extension or self.check_extension(filename):\n",
    "            return self._readfile(filename)        \n",
    "        else:\n",
    "            print(\"Error: filename {} does not match acceptable extensions.\".format(filename))\n",
    "    \n",
    "    def _writefile(self,filename,data):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def writefile(self,filename,data):\n",
    "        return self._writefile(filename,data)\n",
    "        \n",
    "        \n",
    "class CSVHandler(DataFileHandler):\n",
    "    def __init__(self):\n",
    "        #super(CSVHandler,self).__init__([\"csv\",\"CSV\"])\n",
    "        DataFileHandler.__init__(self,[\"csv\",\"CSV\"])\n",
    "        \n",
    "    def _readfile(self,filename):\n",
    "        f=open(filename,\"r\")\n",
    "        first_line = f.readline().rstrip()\n",
    "        fields=first_line.split(\",\")\n",
    "\n",
    "        data=list()\n",
    "\n",
    "        line = f.readline().rstrip()\n",
    "        while line:\n",
    "            items=line.split(\",\")\n",
    "            \n",
    "            row=list()\n",
    "            for item in items:\n",
    "                try:\n",
    "                    d=float(item)\n",
    "                except ValueError:\n",
    "                    d=item\n",
    "                row.append(d)\n",
    "            \n",
    "            data.append(row)\n",
    "            \n",
    "            line = f.readline().rstrip()\n",
    "\n",
    "        f.close()\n",
    "        \n",
    "        my_data=Data()\n",
    "        my_data.set_fields(fields)\n",
    "        my_data.add_data_points(data)\n",
    "        \n",
    "        return my_data\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_handler=CSVHandler()\n",
    "my_data=my_handler.readfile(\"Scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data[10][\"l4_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "What we just build is very similar to Pandas..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Data=pd.read_csv(\"Scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[Data[\"l4_2\"]==10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "We implemented `__getitem__` in our data classes to enable easy access of our data. Lets take a closer look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_list:\n",
    "    def __init__(self,a_list):\n",
    "        self._list=a_list\n",
    "        \n",
    "    def __getitem__(self,key):\n",
    "        print(key)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a lot of nice functionality... but not everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = my_list([5,5,5])\n",
    "\n",
    "obj[1]\n",
    "obj[1,2]\n",
    "obj[1,2,3]\n",
    "obj[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note slicing results in a `slice` object not the slice of the data. Let's look at `slice` closer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice(1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice(1,2,3).start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can detect in `__getitem__` when we get a slice object and use it accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_list:\n",
    "  def __init__(self,a_list):\n",
    "    self._list=a_list\n",
    "\n",
    "  def __getitem__(self, key):\n",
    "    if isinstance(key, slice):\n",
    "        start = key.start or 0\n",
    "        stop = key.stop or len(self._list)\n",
    "        step = key.step or 1        \n",
    "        return [self._list[i] for i in range(start, stop, step)]\n",
    "    elif isinstance(key, int):\n",
    "        return self._list[key]\n",
    "    elif isinstance(key, tuple):\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        raise TypeError "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list([1,2,3,4,5,6,7])[2:6:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to do something more complicated, like handle both `M[i][j]` and `M[i,j]` in the same way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataRow:\n",
    "    def __init__(self,fields,data):\n",
    "        self.__fields=fields\n",
    "        self.__data=data\n",
    "        \n",
    "    def __getitem__(self,key):\n",
    "        return self.__data[self.__fields.index(key)]\n",
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.__fields=list()\n",
    "        self.__data=list()\n",
    "        \n",
    "    def set_fields(self,fields):\n",
    "        self.__fields=fields\n",
    "        \n",
    "    def add_data_point(self,data_point):\n",
    "        if isinstance(data_point,list):\n",
    "            if len(data_point) == len(self.__fields):\n",
    "                self.__data.append(DataRow(self.__fields,data_point))\n",
    "            else:\n",
    "                print(\"Expected {} fields, got {} fields.\".format(len(self.__fields),len(fields)))\n",
    "        else:\n",
    "            print(\"Data Point must be given as a list.\")\n",
    "\n",
    "    def add_data_points(self,data_points):\n",
    "        for data_point in data_points:\n",
    "            self.add_data_point(data_point)\n",
    "            \n",
    "    def fields(self):\n",
    "        return self.__fields\n",
    "    \n",
    "    def __getitem__(self,key):\n",
    "        return self.__data[key]\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy Evaluation\n",
    "\n",
    "Matrix multiplication can be a time consuming operation. What if we only need a few elements of the result of a matrix multiplication? Can we some how only compute the elements we need only? This is where the concept of lazy evaluation can come in handy.\n",
    "\n",
    "Recall the matrix multiplication formula:\n",
    "\n",
    " $C=A \\cdot B$: $C_{ij} = \\sum_{k} A_{ik} B_{kj}$.\n",
    " \n",
    "Note that we actually compute every element of the resultant matrix independently, but in a typical implemenation of multiplication, we'll loop over all elements of resultant matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_matrix(m,n):\n",
    "    return [ [0 for _ in range(m)] for _ in range(n)]\n",
    "\n",
    "def is_matrix(M):\n",
    "    if isinstance(M,list):\n",
    "        row_length=len(M[0])\n",
    "        for row in M:\n",
    "            if not row_length==len(row):\n",
    "                return False\n",
    "    else:\n",
    "        False\n",
    "    return True\n",
    "        \n",
    "\n",
    "def matrix_shape(M):\n",
    "    if is_matrix(M):\n",
    "        m=len(M)\n",
    "        n=len(M[0])\n",
    "        return m,n\n",
    "    else:\n",
    "        0,0\n",
    "\n",
    "def matrix_multiply(M1,M2):\n",
    "    m1,n1=matrix_shape(M1)\n",
    "    m2,n2=matrix_shape(M2)\n",
    "    \n",
    "    if n1==m2:\n",
    "        \n",
    "        M3=zero_matrix(m1,n2)\n",
    "        \n",
    "        # Loop over ALL elements of the resultant matrix\n",
    "        for i in range(m1):\n",
    "            for j in range(n2):\n",
    "                for k in range(n1):\n",
    "                    M3[i][j]+=M1[i][k]*M2[k][j]\n",
    "        return M3\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 =  [ [ 1, 2 ] , [ 2, 3 ] ]\n",
    "M2 =  [ [ 1, 2 ] , [ 2, 3 ] ]\n",
    "\n",
    "matrix_multiply(M1,M2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead we can create a new matrix class that holds the results of a product of two matrices... and only computes the elements it needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lazy_multiplied_matrix:\n",
    "    def __init__(self,M1,M2):\n",
    "        m1,n1=matrix_shape(M1)\n",
    "        m2,n2=matrix_shape(M2)\n",
    "        \n",
    "        assert(n1==m2)\n",
    "        \n",
    "        self._n1=n1\n",
    "        \n",
    "        self._m=m1\n",
    "        self._n=n2\n",
    "        \n",
    "        self._M1=M1\n",
    "        self._M2=M2\n",
    "\n",
    "        # By default the resultant matrix will be composed of Nones, \n",
    "        # indicating that no element is computed.\n",
    "        \n",
    "        self._M3= [ [None for _ in range(self._m)] for _ in range(self._n)]\n",
    "        \n",
    "    def __getitem__(self,key):\n",
    "        if isinstance(key,tuple):\n",
    "            i,j=key\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        if self._M3[i][j]:\n",
    "            return self._M3[i][j]\n",
    "        else:\n",
    "            self._M3[i][j]=0.\n",
    "\n",
    "            for k in range(self._n1):\n",
    "                self._M3[i][j]+=self._M1[i][k]*self._M2[k][j]\n",
    "                \n",
    "            return self._M3[i][j]\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self._M3)\n",
    "    \n",
    "    __repr__ = __str__\n",
    "    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M3=lazy_multiplied_matrix(M1,M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M3[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
